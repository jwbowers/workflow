\documentclass[12pt]{article}
\usepackage{fancyvrb,natbib,url,array,dcolumn,float,booktabs}
\usepackage{hyperref}

\title{A paper is to write}

\author{Jake Bowers\thanks{Many thanks to Kevin Quinn and Cara Wong for direct help on this document, Mika LaVaque-Manty, Ben Hansen, and Mark Fredrickson for many useful discussions on this topic, and Kieran Healy for inspiration from afar.}}

\date{\today}

\newcolumntype{.}{D{.}{.}{1.2}} 

\usepackage[noae,nogin]{Sweave} %Declaring this explicitly so that I can modify the Sweave environment here rather in Sweave.sty which will be c
\DefineVerbatimEnvironment{Sinput}{Verbatim} {xleftmargin=.5em,fontsize=\footnotesize} 
\DefineVerbatimEnvironment{Soutput}{Verbatim}{xleftmargin=.5em,fontsize=\footnotesize} 
\DefineVerbatimEnvironment{Scode}{Verbatim}{xleftmargin=.5em,fontsize=\footnotesize} 
\fvset{listparameters={\setlength{\topsep}{0pt}}} 
\renewenvironment{Schunk}{\vspace{\topsep}}{\vspace{\topsep}} 
\SweaveOpts{keep.source=TRUE}  %Show comments
\fvset{fontsize=\normalsize} %slightly smaller verbatim font

%% These next lines tell latex that it is ok to have a single graphic
%% taking up most of a page, and they also decrease the space arou
%% figures and tables.
\renewcommand\floatpagefraction{.9}
\renewcommand\topfraction{.9}
\renewcommand\bottomfraction{.9}
\renewcommand\textfraction{.1}   
\setcounter{totalnumber}{50}
\setcounter{topnumber}{50}
\setcounter{bottomnumber}{50}
\setlength{\intextsep}{2ex}
\setlength{\floatsep}{2ex}
\setlength{\textfloatsep}{2ex}


\begin{document}
\maketitle


<<initialize,echo=FALSE,results=hide>>= 
##First, just setup the \R environment:

options(SweaveHooks=list(
          fig=function(){
            par(mar=c(3.5, 3, 1.1, 0),
                pty="s",
                mgp=c(1.5,0.5,0),
                oma=c(0,0,0,0))},#,
          echo=function(){options(continue=" ") ##Don't show "+" prompts,
                         options(prompt=" ")}
          ),
        digits=3,
        scipen=8,
        width=100
        )

@ 


\begin{verse}
Do I contradict myself? \\
Very well then I contradict myself, \\
(I am large, I contain multitudes.) \\
\citep{whitman1855song}
\end{verse}

An idea is born in a coffee shop, a seminar, a quiet walk. It is a cold winter in 2011, but the idea energizes the student. The idea is why he went to graduate school.

This idea inspires a seminar paper in the spring. And a conference paper arises from the seminar paper in collaboration with another student in 2012. A dissertation chapter descends from the conference paper in 2013. Other dissertation chapters take up 2014. A submission to a journal with the original co-author and a new collaborator happens in 2015. Revision and resubmission wait until 2017 while harried editors, reviewers and authors strive to balance teaching, service, and life. The three collaborators have luckily found work in three different universities around the world. In 2018 a child is born and a paper is published. In 2020 a graduate student in a coffee shop reads the paper and has an idea that challenges the analysis in the paper. What would happen if only the first author had thought to control for X? Or run one more MCMC chain? Or chosen a different likelihood function? Will the United Nations (now eager to act based the paper) make a wrong move? 

The first author convenes a three way video conference with the other collaborators while commuting home in his flying car. The group must go back to the analyses. Which ones? The ones from 2011? Or 2012? Or 2018? Where are the files? The next day, one member of the group finds some of the files. Now the checks and re-analyses should be easy. Right? The student-now-faculty member is the same person and should remember the reason for those bits of code (or at least should remember which series of mouse clicks were used to produce the numbers for that crucial table). And, of course, the way Microsoft Word/Stata/SPSS/R/LISREL stores files and the way that your Windows/Mac machine reads and writes them is the same, right? (And Windows and Mac are still relevant operating systems.) And the group knows exactly which bit of code produced which table and which figure, right? And they wrote their code following Nagler's Maxims \citet{nagler1995coding} and being following King's Replication Standard \citet{king1995replication} right? 

Just in case one has some doubt about answering these questions, this piece aims to amplify some of what we already ought to know from \citet{nagler1995coding} and \citet{king1995replication}, and to update some of those ideas given current practices, platforms, and propensities.

\section{Why should we believe each other?}

When we call some piece of work ``scientific'' we are talking about how it was done. By calling it ``scientific'' we are also using a short-hand to suggest that (1) the findings of the work are not a matter of opinion and (2) other people could reproduce the findings. That is, what the work represents is not a matter of opinion but is a shared experience --- and an experience shared without respect to the identities of others (although requiring some shared technical training and research resources). This short-hand means that ``scientific'' work should make us change how we act --- or at least, it ought to stand on stronger epistemological ground than other claims about experiences which ought to be shared or shareable.

Assume we want other scientists to believe us when we say something. More narrowly, assume we want other people to believe us when we say something about data: ``data'' here can be words, numbers, musical notes, images, ideas, etc \ldots The point is that we are making some claims about patterns that we see in some collection of stuff. Now, it might be easy to convince other people that ``this collection of stuff is different from this collection of stuff'' if those people were looking over our shoulders the whole time that we made decisions about collecting the stuff and analyzed it [where ``analyze'' means something like ``break it up into understandable parts'']. Unfortunately, we can't assume that people are willing to shadow a researcher throughout her career. Rather, we do our work alone or in small groups and want to convince other distant people about our analyses.

Now, say your collections of stuff are large or complex and where your chosen tools of analyses are computer programs. How can we convince people that what we did with some data with some program is credible: not a matter of whim or opinion, and reproducible by others who didn't shadow us as we wrote our papers? Here are a few concrete actions that people can take to enhance the believeability of their work. In addition, these actions make collaboration within research groups more effective (since believeability comes in part from reproducibility and research groups often need to be able to reproduce in part or in whole what different people in the group have done).

\section{Show me the data.}
All files containing commands operating on data must refer to a data file. A reference to a data file is a line of code the analysis program will use to operate on (``load''/ ``open'' / ``get'' / ``use'') the data file. One should not have to edit this line on different computers or platforms in order to execute this command.  Using R, for example, all analysis files should have load('thedata.rda') or \Verb+read.csv('http://www.mywebsite.org/Data/thedata.csv')+ or some equivalent line in them, and 'thedata.csv' should be stored in some place easy to find (like in the same directory as the file or perhaps in 'Data/thedata.rda'). 

Where should you store the data files? A very obvious solution is to always make sure that the data file used by a command file is in the same directory as the command file. More elegant solutions (pointed to below) require all co-authors to have the same directory structure so that load('Data/thedata.rda') means the same thing on all computers used to work on said project. 

The principle of modularity \cite{nagler1995coding} suggests that you separate data cleaning, processing, recoding, and merging from analysis in different files. So, perhaps your analysis oriented files will load('cleandata.rda') or something but with a comment in the code telling the future you (among others) that cleandata.rda was created from create-cleandata.R which in turn begins with read.csv('dirtydata.csv') which, from a comment in the file, was downloaded from \url{http://www.greatfreedata.gov/thedata?dirtydata.csv} on April 1, 2011. Such a data processing file will typically end with something like \Verb+save('cleandata.rda')+ so that we are doubly certain about the provenance of the data.

Now, if in 5 years we wonder where 'cleandata.rda' came from, we might \Verb+ grep cleandata *.R+ to search for occurrences of this file on our Unix/OS X system. However, if such searching among files is a burden, and even nicer solution is to maintain a file for each project called ``MANIFEST.txt'' or ``INDEX.txt'' or ``README.txt'' which lists the data and command files with brief descriptions of their functions and relations. 

The principle regarding data is to know where the data came from and what operations were performed on which set of data. I have seen command files which do not begin with a call to load data and I have despaired. What is the meaning of \Verb+please-fit(var1 with var2)+ if I do not know where var1 var2 come from.\footnote{The command \Verb+please-fit+ comes from the MayIPleaseDoStatistics package for R which emphasizes politeness in data analysis. It is highly recommended for use with toddlers.}

\section{Code not Clicking}
All tables and graphs should be as much as possible generated from code and not clicking (let alone copying and pasting). If I wanted to re-create the figure you created but with red lines, and only for people in the South, I should be able to do so with just a few edits to the code.

Using R, for example, I might specify that the file \Verb+fig1.pdf+ was produced by the command, where the \Verb+please-plot+ function was loaded elsewhere.

\begin{verbatim}
pdf('fig1.pdf')
please-plot(outcome by explanatory)
dev.off()
\end{verbatim}

Now, in the future if I wonder how ``that plot on page 10'' was created, if I suitably commented my manuscript or inserted text into my MANIFEST.txt file I will know (1) ``that plot'' is from a file called ``fig1.pdf'' and (2) fig1.pdf was created in \Verb+figs1and2.R+. In the future, if I wanted to quickly change fig1.pdf, I could edit the commands quickly and easily to do so. [Another good practice is to name the files descriptively, so that we don't in fact have ``fig1.pdf'' but ``political participation by education in the south.pdf'' although such a name may prove burdensome to operating systems which do not care for spaces in file names or to folks who are used to typing full filenames rather than using command line completion facilities in modern shells.]

An even nicer way to ensure that figures and tables are reproducible or easily modifiable by your older and wiser but more harried self is to use literate programming. For example, to produce the Figure~\ref{fig:giniprot}, I insert the following chunk of code into the  LaTeX document, and then I asked R to process the document, and then produce a pdf file in which the code has disappeared to be replaced with an actual figure.\footnote{One can insert the same code chunk in an OpenOffice document and use the odfWeave package to produce OpenOffice documents in which figures and tables replace code. One may also use the LyX interface to LaTeX to write LaTeX documents within a WYSIWYG environment.}

<<read.data,echo=FALSE,results=hide>>=

##This read.csv line is slightly more complex than needed because of
##the particular encoding used for characters in the source file.

dem.nations.df<-read.csv(url("http://www.hks.harvard.edu/fs/pnorris/Data/Democracy%20CrossNational%20Data/Democracy%20Crossnational%20Data%20Spring%202009.csv",encoding="ISO_8859-1"),as.is=TRUE)

row.names(dem.nations.df)<-dem.nations.df$Natabrv ##make the row names more helpful

good.df<-na.omit(dem.nations.df[,c("Gini2004","protac2000","Nation","meanpr")])
@ 

<<fig1code,echo=TRUE,fig=FALSE,width=3,height=3>>=
##The code to produce the following figure
par(bty="n",xpd=TRUE,pty="s",tcl=-.25)
with(good.df,plot(Gini2004/100,protac2000,
     xlab='Gini Coefficient 2004 (UNDP)',
     ylab='Mean Protest Activities\n(World Values Survey 1980-2000)',
     cex=.8))

with(good.df[c("EGY","JOR","USA","SWE","CHL"),],
     text(Gini2004/100,protac2000,labels=Nation,srt=0,cex=.6,pos=3,offset=.1))
@
 
\begin{figure}[ht]
  \begin{center}
<<fig1plot,echo=FALSE,fig=TRUE,width=3,height=3>>= 
<<fig1code>>
@
    \caption{Protest activity by income inequality from \citep{norris2009data}.}\label{fig:giniprot}
  \end{center}
\end{figure}


The principle here is to know where tables and figures came from --- to know what commands created which figures and tables.

\section{Fishing rods and not fish}
The source code of any pdf document exchanged by the group must be available and executable. Say you run some command and then make a table or a graph. Then you produce a nice little report on your work for use among the working group. Eventually we want to use pieces of that report (tables, graphs, paragraphs) in a publishable paper. Thus, that report must not have been created using copying and pasting. It must be created using LaTeX (or HTML or OpenOffice or something else that the working group standardizes on). And, in fact, it must be created using the reproducible markup system like Sweave (if you are using LaTeX and R as your working group tools) \citep{Leis:2005}. Alternatively, you can put comments into your report detailing where the figures and tables came from (i.e. which command file produced them). Or include details about which code produced which figures in your MANIFEST.txt.

In order to know that ``that plot on page 10'' is from a file called ``fig1.pdf'' you need to document it somehow. I can imagine a system with very disciplined use of a word processor (like Open Office or Word) --- perhaps using special auxiliary ``listoffigures.txt'' files or something. In my experience, it is much easier to just use LaTeX (which can be used in a very user friendly way via LyX).

The Sweave system is even nicer because you can have a LaTeX file with R code right inside of it! I showed Sweave with plotting above so here is an example in which a regression table is produced automagically:

<<maketable, echo=FALSE, results=tex>>=
##source("http://artsci.wustl.edu/~jgill/Models/graph.summary.R")

lm1<-lm(protac2000~I(Gini2004/100)+meanpr,data=good.df)

themat<-cbind(summary(lm1)$coef[,c("Estimate","Std. Error")],confint(lm1))
n<-length(lm1$fitted.values)
est.sigma<-round(summary(lm1)$sigma,3)
library(xtable)

colnames(themat)[3:4]<-c("~{}","~{}")
row.names(themat)<-c("Intercept","Income Inequality (lower=more equal)","Mean Political Rights (lower=more rights)")
thextab<-xtable(themat,align=c("l",rep(".",4)),
                caption="People living in countries with unequal
  income distributions report less protest activity to World Values
  Survey interviewers than people living in countries with relatively
  more equal income distributions, adjusting for average political
  rights as measured by Freedom House 1980--2000. Data from \\citep{norris2009data}.",label="tab:protest") 



print(thextab,include.colnames=FALSE,
      hline.after=NULL,
      add.to.row=list(pos=list(0,3),
                command=c("\\toprule \n & \\multicolumn{1}{c}{Coef} & \\multicolumn{1}{c}{Std. Err.} 
& \\multicolumn{2}{c}{95\\% CI} \\\\ \\cmidrule(r){2-5} ", 
                  paste("& \\multicolumn{4}{c}{n: ",n,",   $\\hat{\\sigma}$:",est.sigma,"} \\\\ \\bottomrule"))
                )
      )
@


Right now it is hard to beat Sweave as a system for enhancing the collaboration of research groups doing quantitative work in political science. Something will make our lives easier than Sweave (or odfWeave) in the future. Then we'll change.


\section{Enabling revision. Preventing clobbering.}

Group work requires version control.\footnote{See X for more
  discussion of what version control is.} Many people are familiar
with ``Track Changes'' feature in modern WYSIWYG word processors or the fact that
Dropbox allows one to recover previous versions of files. These are
both kinds of version control. When collaborating with yourself or
others, it is useful to see what has changed, to feel free to
experiment and then to dump the experiment in favor of previous work,
to have multiple ``releases'' of the same document (one to MPSA, one
to APSR, one to your parents) without requiring that spawn many copies
of the same document and risk confusion and clobbering. Clobbering is
what happens when your future self or your other collaborators saves
an old version of a file over a new version --- erasing good work by
accident.

Of course if you rely on Dropbox or ``track changes'' for version
control, you must communicate with other folks in your group before
you edit existing files. Only one of you can edit and save a given
file at a time. This prevents your work (or your colleagues work) from
getting lost when you both try to save the same file on top of each
other. If you find that you are needing to work on the same files at
the same time, then you should work on establishing your own shared
version control system. Free options include launchpad, github,
sourceforge for open source projects (i.e. papers you are writing
which you are happy to share with others). Each of those services
include paid versions too. One may also use Dropbox as a kind of
server for version control: checking out files from the Dropbox
directory into a local working directory. (Notice that this is
different from directly working on files within your Dropbox managed
directories.)

% (the bazaar system appears particularly well suited for use with DropBox http://marcioandreyoliveira.blogspot.com/2009/05/get-your-own-bazaar-hosting-service-for.html)


We use subversion with our own research group, and I use it for all of
my own projects. Subversion and bazaar and git are all great. They
mainly differ in the extent to which you need to run a
server. Subversion requires a server and we are lucky that the
National Center for Supercomputing Applications provides such a server
for us. However, the price of such hosting may not be that much using
one of the many webhosting services out there. 

Fancy version control systems are not required, however. I suspect
that Google Docs allows a kind of version tracking and collaboration
as well.  An excellent, simple, and robust version control system is
to merely rename your files with the date and time of saving them:
thedoc.tex becomes thedoc25092009-22:40.tex.  If you are wise enough to have saved your documents as plain text (Such as LaTeX source (with or without R/Stata code chunks) \footnote{A quick Google search of ``Sweave for Stata'' turned up lots of resources for literate programming with Stata.} then you can easily compare documents using the many utilities available for comparing text files [FileMerge on OS X is pretty, but ediff and diff for Unix are very useful, I am sure that Windows has many other options]. Adobe Acrobat allows one to compare differences in pdf files. OpenOffice supports a ``Compare Documents'' option.

When you reach certain milestones you can rename the file accordingly:
thedocAPSA2009.tex [for the one sent to discussants at APSA] or
thedocAPSR2015.tex [for the version eventually sent to the APSR six
years after you presented it at APSA]. The systems I mentioned above
all allow this kind of thing and are much more elegant and capable,
but you can do it by hand too as long as you don't mind taking up a
lot of disk space and having many many ``thedoc...''  files around.

\section{Write code for your audience.}
Read \citet{nagler1995coding}. Comment your code. Luckily, if you are
using a literate programming practice (Sweave, odfWeave, using R2HTML,
etc..), you can write paragraphs to surround your code as well a
technical comments in the code itself. If you are not using a strictly
literate programming practice then use whatever commenting protocol
exists in your analysis language.

A given analysis of a given collection is a long series of
decisions. You need to be able to justify them. Often you justify them
in the paper you are writing (in the text surrounding the R code
chunks in your Sweave document). Some decisions will be too small and
technical for inclusion in the paper itself. These need to be
documented in the code itself.

Using R within Sweave, for example, the comment is marked using the pound sign. Notice that I've left in a regression not run for the paper directly, but run as a part of the due diligence process of writing the paper.

\begin{Verbatim}
<<reg1>> =
##Fitting the regression with x/1000 for ease of interpretation
thelm<-lm(y~I(x/1000)+z,data=fabulous.df)
##Fits using a quadratic term as suggested by Blah(1865) did not enhance the fit of the model
##thelmsq<-lm(y~I(x/1000)^2+z,data=fabulous.df)
@
\end{Verbatim}

If you need to sleuth down something more than a small detail, but yet the sleuthing is really a footnote to the article, then you can create another file to explore and report on those questions for the research group. The writing in such a memo can be more informal, but the norms of reproducibility ought to be the same as for the main paper. After all you will be releasing both documents (probably) publicly upon publication of the article if not before.

\section{Unit Testing}

Imagine that you reported  bootstrap confidence intervals in your famous article. Now the statisticians at the UN are worrying about your bootstrap confidence interval. You'd like to evaluate your bootstrap procedure. Although nice code exists for bootstrapping linear models, no nice code exists to bootstrap the bootstrap. Of course, the code required is not complex, but since you are writing your own code you worry about getting it right. Now, 9 years after the idea, you've had lots of time to appreciate problems arising from bugs and errors in data analysis code. 

Now, if you had a moment to think in between teaching that new class, reading books for the awards committee, reading application files for the admissions committee, staying home with a sick child, and your own current research, you might say to yourself, ``Before I write new code, I should write a test of the code. I should write a little bit of code that let's me know that my double-bootstrap procedure actually does what it is supposed to do.''

Of course, this idea, like most others is not new. When large groups of programmers write code for multi-million dollar programs the question about avoiding error looms large. The idea of \href{http://en.wikipedia.org/wiki/Test-driven_development}{test driven development} and the idea that one ought to create tests of \href{http://en.wikipedia.org/wiki/Unit_testing}{small parts of one's code} arose to address such concerns. For the social scientist collaborating with her future self and/or a small group of collaborators.

Here is an example of this idea in a very simple form. I want to write a function to multiply a number by 2. If my function works, when I give it the number 4, I should see it return the number 8 and when I give it -4, I should get -8.

<<unit.test>>=
times.2.fn<-function(thenumber){
  thenumber+2
}

test.times.2.fn<-function(){
  if(times.2.fn(thenumber=4) == 8 &
     times.2.fn(thenumber=-4) == -8){
    print("It works!")
  }else{print("It does not work!")}
}


test.times.2.fn()
@ 

Ack! I mistyped ``+'' for ``*''. Good thing I wrote the test!








\section{File Naming}

Name your files with evocative and descriptive names. Your
collaborators are less likely to call you at midnight asking for help
if your files are named ``regressions.R'' than if your files are
called ``temp9'' or ``supercalifragilisticexpialidocious'' (note the
use of the extension .R to tell us that the file contains R
commands. use extensions like this as a standard practice to help you
and your computer get along.)

(other stuff I've forgotten?)

\section{Exemplars}

Lots of people are thinking about ``reproducible research'' and ``literate programming'' these days. Google those terms. Of course the devil is the details: Here I list a few of my own attempts at enabling reproducible research. You'll find many other inspiring examples on the web.

I have experimented with three systems so far: (1) for one paper we simply included a Sweave document and data files into a compressed archive \cite{bowers2005dataverse}; (2) for another more computing intensive paper we assembled a set of files which enabled reproduction of our results using the ``make'' system \citep{bowers2008dataverse}; and (3) recently I have tried the ``compendium'' approach \citep{gentleman2005reproducible,gentleman2007statistical} which embeds an academic paper with the R package system \cite{bowers2011dataverse}. The benefit of this last system is that one is not required to have access to unix: one may download, run, and view the paper from within R --- which is platform independent. 


\section{Constructive Collaboration}

We all always collaborate. Many of us collaborate with groups of people at one moment in time as we race to produce a paper in time for some deadline. All of us collaborate with ourselves over time. An idealized version of self-collaboration goes something like this: We begin a project with a few notes. We write a conference paper. We revise this paper and send it to a journal. The journal asks for revisions. We revise and resubmit. Our paper is accepted. We revise a bit more. The paper is published. Later another scholar reacts to our paper. We write another paper based on said reactions (draft, conference paper, submission, revision, acceptance, revision). These processes occur over years of time. So, I collaborate with a self 5 or 10 or even more years hence when I write a paper. [Ask anyone who has turned their dissertation into a book how long it took from them from dissertation prospectus to physical published book for an example of a common time span in which self-collaboration is required.]

The time-frames over which collaboration are required --- whether
among a group of people working together or within a single scholar's
productive life --- are much longer than any given version of any
given software will easily exist. All except for plain text. Thus,
even as we extol version control systems, one must have a way to
ensure future access to them in a form that will still be around when
the cockroaches take over political science departments.\footnote{
  (and thereby finally make Ctrl-a Ctrl-x Esc-x Ctrl-c a reasonable
  way to instruct Emacs to do something
  (\url{http://kieran.healy.usesthis.com/} )}

In the end, following these practices allows your analyses of your collections to be credible --- and, in the case of criticism, you can always tell antagonists to go redo your analysis if they really don't believe you.  Let me end with the most pithy statement in favor of the idea that collaboration is at the heart of our endeavor that I have found:

"[I]f the empirical basis for an article or book cannot be reproduced, of what use to the discipline are its conclusions? What purpose does an article like this serve?'' \cite[445]{king1995replication}

\bibliographystyle{asa} 
\bibliography{/Users/jwbowers/Documents/BIB/trunk/big}


\end{document}
<<>>=
options(prompt="> ",continue="+ ")
@ 
